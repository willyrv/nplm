{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data for training\n",
    "\n",
    "This notebook illustrates the process of creating a dataset from the arXiv.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dictionary(dict):\n",
    "    \"\"\"\n",
    "    Extends python dictionary in order to have\n",
    "    index --> word\n",
    "    but also\n",
    "    word --> index\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(dictionary, self).__init__()\n",
    "        self.index = {}\n",
    "        self.size = 0\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        super(dictionary, self).__setitem__(key, value)\n",
    "        self.index[value] = key\n",
    "        self.size += 1\n",
    "    \n",
    "    def __delitem__(self, key):\n",
    "        value = super().pop(key)\n",
    "        ignore = self.index.pop(value)\n",
    "        self.size -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(corpus, context_size, dictionary, fixed_dictionary=False):\n",
    "    list_of_points = []\n",
    "    for document in corpus:\n",
    "        list_of_points += process_document(document, context_size, dictionary, fixed_dictionary)\n",
    "    return list_of_points\n",
    "\n",
    "\n",
    "def process_document(document, context_size, dictionary, fixed_dictionary=False):\n",
    "    \"\"\"\n",
    "    Given a dictionary, extract the tuples of words of length equal to\n",
    "    context_size. Each word is represented by a unique integer number.\n",
    "    If fixed_dictionary is True, only take consecutive tuples of words \n",
    "    being (all of them) in the dictionary.\n",
    "    Example: \n",
    "        document = \"This is a new document\"\n",
    "        context_size = 4\n",
    "        dictionary = {\n",
    "            0: \"this\",\n",
    "            1: \"is\",\n",
    "            2: \"a\",\n",
    "            3: \"new\",\n",
    "            4: \"document\"\n",
    "        }\n",
    "        \n",
    "        return\n",
    "            [(0, 1, 2, 3), (1, 2, 3, 4)]\n",
    "    \"\"\"\n",
    "    text = document.lower()\n",
    "    p = re.compile(\"[a-z]+\")\n",
    "    tokens = p.findall(text)\n",
    "    list_of_points = []\n",
    "    for i in range(len(tokens) - context_size + 1):\n",
    "        data_point = [0 for l in range(context_size)]\n",
    "        add_new_data_point = True\n",
    "        for j in range(context_size):\n",
    "            k = i+j\n",
    "            if tokens[k] not in dictionary.index:\n",
    "                if fixed_dictionary:\n",
    "                    # only takes series of words in the dictionary\n",
    "                    add_new_data_point = False\n",
    "                    break\n",
    "                else:\n",
    "                    new_Ix = dictionary.size\n",
    "                    dictionary[new_Ix] = tokens[k]\n",
    "            data_point[j] = dictionary.index[tokens[k]]\n",
    "        if add_new_data_point:\n",
    "            list_of_points.append(tuple(data_point))\n",
    "    return list_of_points\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some important values\n",
    "CONTEXT_SIZE = 4\n",
    "DICT_SIZE = 17000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the arXiv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"./arxiv_articles.csv\", sep=\"|\")\n",
    "data = pd.read_csv(\"./arxiv_articles_sample.csv\", sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_primary_category</th>\n",
       "      <th>summary</th>\n",
       "      <th>published</th>\n",
       "      <th>updated</th>\n",
       "      <th>general_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/1502.02721v1</td>\n",
       "      <td>In-situ measurements of the radiation stabilit...</td>\n",
       "      <td>P. A. Gerakines;R. L. Hudson;M. H. Moore;J. -L...</td>\n",
       "      <td>astro-ph.IM</td>\n",
       "      <td>We present new kinetics data on the radiolytic...</td>\n",
       "      <td>2015-02-09T23:03:10Z</td>\n",
       "      <td>2015-02-09T23:03:10Z</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/1503.01540v1</td>\n",
       "      <td>Finding meteorite impacts in Aboriginal oral t...</td>\n",
       "      <td>Duane W. Hamacher</td>\n",
       "      <td>physics.hist-ph</td>\n",
       "      <td>Aboriginal stories dating back many thousands ...</td>\n",
       "      <td>2015-03-05T05:21:09Z</td>\n",
       "      <td>2015-03-05T05:21:09Z</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/1909.09824v1</td>\n",
       "      <td>Desperate times call for desperate measures: g...</td>\n",
       "      <td>Sokbae Lee;Yuan Liao;Myung Hwan Seo;Youngki Shin</td>\n",
       "      <td>econ.GN</td>\n",
       "      <td>We investigate state-dependent effects of fisc...</td>\n",
       "      <td>2019-09-21T13:42:17Z</td>\n",
       "      <td>2019-09-21T13:42:17Z</td>\n",
       "      <td>econ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/1809.07292v2</td>\n",
       "      <td>Online control of the false discovery rate in ...</td>\n",
       "      <td>David S. Robertson;James M. S. Wason</td>\n",
       "      <td>stat.ME</td>\n",
       "      <td>Modern biomedical research frequently involves...</td>\n",
       "      <td>2018-09-19T16:37:46Z</td>\n",
       "      <td>2018-09-26T17:08:01Z</td>\n",
       "      <td>stat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/1902.10021v1</td>\n",
       "      <td>Gig Economy: A Dynamic Principal-Agent Model</td>\n",
       "      <td>Zsolt Bihary;Péter Kerényi</td>\n",
       "      <td>econ.GN</td>\n",
       "      <td>The gig economy, where employees take short-te...</td>\n",
       "      <td>2019-02-26T16:05:06Z</td>\n",
       "      <td>2019-02-26T16:05:06Z</td>\n",
       "      <td>econ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id  \\\n",
       "0  http://arxiv.org/abs/1502.02721v1   \n",
       "1  http://arxiv.org/abs/1503.01540v1   \n",
       "2  http://arxiv.org/abs/1909.09824v1   \n",
       "3  http://arxiv.org/abs/1809.07292v2   \n",
       "4  http://arxiv.org/abs/1902.10021v1   \n",
       "\n",
       "                                               title  \\\n",
       "0  In-situ measurements of the radiation stabilit...   \n",
       "1  Finding meteorite impacts in Aboriginal oral t...   \n",
       "2  Desperate times call for desperate measures: g...   \n",
       "3  Online control of the false discovery rate in ...   \n",
       "4       Gig Economy: A Dynamic Principal-Agent Model   \n",
       "\n",
       "                                             authors arxiv_primary_category  \\\n",
       "0  P. A. Gerakines;R. L. Hudson;M. H. Moore;J. -L...            astro-ph.IM   \n",
       "1                                  Duane W. Hamacher        physics.hist-ph   \n",
       "2   Sokbae Lee;Yuan Liao;Myung Hwan Seo;Youngki Shin                econ.GN   \n",
       "3               David S. Robertson;James M. S. Wason                stat.ME   \n",
       "4                         Zsolt Bihary;Péter Kerényi                econ.GN   \n",
       "\n",
       "                                             summary             published  \\\n",
       "0  We present new kinetics data on the radiolytic...  2015-02-09T23:03:10Z   \n",
       "1  Aboriginal stories dating back many thousands ...  2015-03-05T05:21:09Z   \n",
       "2  We investigate state-dependent effects of fisc...  2019-09-21T13:42:17Z   \n",
       "3  Modern biomedical research frequently involves...  2018-09-19T16:37:46Z   \n",
       "4  The gig economy, where employees take short-te...  2019-02-26T16:05:06Z   \n",
       "\n",
       "                updated general_category  \n",
       "0  2015-02-09T23:03:10Z         astro-ph  \n",
       "1  2015-03-05T05:21:09Z          physics  \n",
       "2  2019-09-21T13:42:17Z             econ  \n",
       "3  2018-09-26T17:08:01Z             stat  \n",
       "4  2019-02-26T16:05:06Z             econ  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "mydict = dictionary()\n",
    "dataset = process_corpus(data['summary'], CONTEXT_SIZE, mydict)\n",
    "t = time.time() - s\n",
    "print(\"Done in {} seconds\".format(int(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3218"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13528"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1, 2, 3),\n",
       " (1, 2, 3, 4),\n",
       " (2, 3, 4, 5),\n",
       " (3, 4, 5, 6),\n",
       " (4, 5, 6, 7),\n",
       " (5, 6, 7, 8),\n",
       " (6, 7, 8, 9),\n",
       " (7, 8, 9, 10),\n",
       " (8, 9, 10, 11),\n",
       " (9, 10, 11, 12)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3\n",
       "0  0  1  2  3\n",
       "1  1  2  3  4\n",
       "2  2  3  4  5\n",
       "3  3  4  5  6\n",
       "4  4  5  6  7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6       924\n",
       "9       607\n",
       "22      355\n",
       "76      320\n",
       "65      313\n",
       "       ... \n",
       "2058      1\n",
       "11        1\n",
       "2066      1\n",
       "1517      1\n",
       "2011      1\n",
       "Name: 0, Length: 3179, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of occurrences for each word\n",
    "word_counts = data_df.iloc[:, 0].value_counts()\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the four most frequent words: ('the', 'of', 'and', 'a')\n"
     ]
    }
   ],
   "source": [
    "w1 = word_counts.keys()[0]\n",
    "w2 = word_counts.keys()[1]\n",
    "w3 = word_counts.keys()[2]\n",
    "w4 = word_counts.keys()[3]\n",
    "print(\"These are the four most frequent words: {}\".format((mydict[w1], mydict[w2], mydict[w3], mydict[w4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we want to keep only a subset of all the words\n",
    "# we define a fixed size for the dictionary and we \n",
    "# keep the words, starting from the most frequent ones\n",
    "\n",
    "words2keep = word_counts.keys()[:DICT_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   6,    9,   22,   76,   65,   13,  102,    0,   49,  130,\n",
       "            ...\n",
       "            2018, 2026, 2034, 2050, 1549, 2058,   11, 2066, 1517, 2011],\n",
       "           dtype='int64', length=3179)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we create a new dictionary with the\n",
    "# words selected in the previous step\n",
    "new_dictionary = dictionary()\n",
    "for i in range(len(words2keep)):\n",
    "    new_dictionary[i] = mydict[words2keep[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0 seconds\n"
     ]
    }
   ],
   "source": [
    "# With the new dictionary, build the new training dataset\n",
    "\n",
    "# Creating the training dataset using series of 4 words \n",
    "# appearing in the text\n",
    "s = time.time()\n",
    "new_dataset = process_corpus(data['summary'], CONTEXT_SIZE, new_dictionary, fixed_dictionary=True)\n",
    "t = time.time() - s\n",
    "print(\"Done in {} seconds\".format(int(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13463"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3179"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dictionary.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 86, 40, 1175),\n",
       " (86, 40, 1175, 19),\n",
       " (40, 1175, 19, 11),\n",
       " (1175, 19, 11, 0),\n",
       " (19, 11, 0, 1670),\n",
       " (11, 0, 1670, 2032),\n",
       " (0, 1670, 2032, 1),\n",
       " (1670, 2032, 1, 223),\n",
       " (2032, 1, 223, 3175),\n",
       " (1, 223, 3175, 1037)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrate how the data is encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We present new kinetics data on the radiolytic destruction of amino acids measured in situ with infrared spectroscopy. Samples were irradiated at 15, 100, and 140 K with 0.8-MeV protons, and amino-acid decay was followed at each temperature with and without H$_2$O present. Observed radiation products included CO$_2$ and amines, consistent with amino-acid decarboxylation. The half-lives of glycine, alanine, and phenylalanine were estimated for various extraterrestrial environments. Infrared spectral changes demonstrated the conversion from the non-zwitterion structure NH$_2$-CH$_2$(R)-COOH at 15 K to the zwitterion structure $^+$NH$_3$-CH$_2$(R)-COO$^-$ at 140 K for each amino acid studied.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'present', 'new', 'kinetics']\n"
     ]
    }
   ],
   "source": [
    "first_words = new_dataset[0]\n",
    "print([new_dictionary[i] for i in first_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'the',\n",
       " 1: 'of',\n",
       " 2: 'and',\n",
       " 3: 'a',\n",
       " 4: 'to',\n",
       " 5: 'in',\n",
       " 6: 'is',\n",
       " 7: 'we',\n",
       " 8: 'for',\n",
       " 9: 'that',\n",
       " 10: 'this',\n",
       " 11: 'on',\n",
       " 12: 'are',\n",
       " 13: 'with',\n",
       " 14: 'by',\n",
       " 15: 'from',\n",
       " 16: 'as',\n",
       " 17: 'be',\n",
       " 18: 'which',\n",
       " 19: 'data',\n",
       " 20: 'an',\n",
       " 21: 'model',\n",
       " 22: 'can',\n",
       " 23: 'method',\n",
       " 24: 'it',\n",
       " 25: 'our',\n",
       " 26: 'at',\n",
       " 27: 'based',\n",
       " 28: 'results',\n",
       " 29: 'two',\n",
       " 30: 'paper',\n",
       " 31: 'also',\n",
       " 32: 'have',\n",
       " 33: 'these',\n",
       " 34: 'using',\n",
       " 35: 's',\n",
       " 36: 'show',\n",
       " 37: 'methods',\n",
       " 38: 'time',\n",
       " 39: 'models',\n",
       " 40: 'new',\n",
       " 41: 'not',\n",
       " 42: 'such',\n",
       " 43: 'mass',\n",
       " 44: 'when',\n",
       " 45: 'high',\n",
       " 46: 'all',\n",
       " 47: 'between',\n",
       " 48: 'than',\n",
       " 49: 'c',\n",
       " 50: 'more',\n",
       " 51: 'selection',\n",
       " 52: 'both',\n",
       " 53: 'class',\n",
       " 54: 'm',\n",
       " 55: 'one',\n",
       " 56: 'problem',\n",
       " 57: 'case',\n",
       " 58: 'most',\n",
       " 59: 'large',\n",
       " 60: 'where',\n",
       " 61: 'well',\n",
       " 62: 'first',\n",
       " 63: 'other',\n",
       " 64: 'but',\n",
       " 65: 'through',\n",
       " 66: 'estimation',\n",
       " 67: 'distribution',\n",
       " 68: 'non',\n",
       " 69: 'has',\n",
       " 70: 'proposed',\n",
       " 71: 'learning',\n",
       " 72: 'algorithms',\n",
       " 73: 'number',\n",
       " 74: 'studies',\n",
       " 75: 'will',\n",
       " 76: 'was',\n",
       " 77: 'positive',\n",
       " 78: 'used',\n",
       " 79: 'under',\n",
       " 80: 'function',\n",
       " 81: 'or',\n",
       " 82: 'conditional',\n",
       " 83: 'observed',\n",
       " 84: 'provide',\n",
       " 85: 'their',\n",
       " 86: 'present',\n",
       " 87: 'density',\n",
       " 88: 'k',\n",
       " 89: 'different',\n",
       " 90: 'however',\n",
       " 91: 'i',\n",
       " 92: 'set',\n",
       " 93: 'study',\n",
       " 94: 'risk',\n",
       " 95: 'functions',\n",
       " 96: 'into',\n",
       " 97: 'many',\n",
       " 98: 'result',\n",
       " 99: 'some',\n",
       " 100: 'structure',\n",
       " 101: 'dimensional',\n",
       " 102: 'effects',\n",
       " 103: 'how',\n",
       " 104: 'observations',\n",
       " 105: 'treatment',\n",
       " 106: 'estimate',\n",
       " 107: 'wide',\n",
       " 108: 'there',\n",
       " 109: 'theory',\n",
       " 110: 'low',\n",
       " 111: 'work',\n",
       " 112: 'price',\n",
       " 113: 'state',\n",
       " 114: 'framework',\n",
       " 115: 'rate',\n",
       " 116: 'cancer',\n",
       " 117: 'known',\n",
       " 118: 'use',\n",
       " 119: 'probability',\n",
       " 120: 'associated',\n",
       " 121: 'propose',\n",
       " 122: 'been',\n",
       " 123: 'general',\n",
       " 124: 'parameters',\n",
       " 125: 'spectral',\n",
       " 126: 'simple',\n",
       " 127: 'process',\n",
       " 128: 'behavior',\n",
       " 129: 'dna',\n",
       " 130: 'effect',\n",
       " 131: 'values',\n",
       " 132: 'growth',\n",
       " 133: 'memory',\n",
       " 134: 'main',\n",
       " 135: 'recent',\n",
       " 136: 'its',\n",
       " 137: 'population',\n",
       " 138: 'given',\n",
       " 139: 'efficient',\n",
       " 140: 'matrix',\n",
       " 141: 'if',\n",
       " 142: 'value',\n",
       " 143: 'working',\n",
       " 144: 'procedure',\n",
       " 145: 'algorithm',\n",
       " 146: 'find',\n",
       " 147: 'stars',\n",
       " 148: 'type',\n",
       " 149: 'system',\n",
       " 150: 'assets',\n",
       " 151: 'scale',\n",
       " 152: 'test',\n",
       " 153: 'specific',\n",
       " 154: 'bayesian',\n",
       " 155: 'best',\n",
       " 156: 'regression',\n",
       " 157: 'optimal',\n",
       " 158: 'over',\n",
       " 159: 'analysis',\n",
       " 160: 'binary',\n",
       " 161: 'imf',\n",
       " 162: 'approach',\n",
       " 163: 'star',\n",
       " 164: 'may',\n",
       " 165: 'cell',\n",
       " 166: 'space',\n",
       " 167: 'complex',\n",
       " 168: 'r',\n",
       " 169: 'numerical',\n",
       " 170: 'investigate',\n",
       " 171: 'flux',\n",
       " 172: 'consider',\n",
       " 173: 'financial',\n",
       " 174: 'computational',\n",
       " 175: 'only',\n",
       " 176: 'simulation',\n",
       " 177: 'galaxies',\n",
       " 178: 'significant',\n",
       " 179: 'then',\n",
       " 180: 'evidence',\n",
       " 181: 'particular',\n",
       " 182: 'various',\n",
       " 183: 'sample',\n",
       " 184: 'line',\n",
       " 185: 'halo',\n",
       " 186: 'control',\n",
       " 187: 'fitting',\n",
       " 188: 'acid',\n",
       " 189: 'systems',\n",
       " 190: 'application',\n",
       " 191: 'each',\n",
       " 192: 'assumptions',\n",
       " 193: 'factors',\n",
       " 194: 'hypotheses',\n",
       " 195: 'applications',\n",
       " 196: 'information',\n",
       " 197: 'energy',\n",
       " 198: 'carlo',\n",
       " 199: 'while',\n",
       " 200: 'monte',\n",
       " 201: 'optimization',\n",
       " 202: 'interest',\n",
       " 203: 'very',\n",
       " 204: 'distributions',\n",
       " 205: 'support',\n",
       " 206: 'review',\n",
       " 207: 'expression',\n",
       " 208: 'develop',\n",
       " 209: 'site',\n",
       " 210: 'higher',\n",
       " 211: 'genes',\n",
       " 212: 'sampling',\n",
       " 213: 'long',\n",
       " 214: 'provides',\n",
       " 215: 'apply',\n",
       " 216: 'svm',\n",
       " 217: 'generated',\n",
       " 218: 'several',\n",
       " 219: 'performance',\n",
       " 220: 'recently',\n",
       " 221: 'previous',\n",
       " 222: 'estimated',\n",
       " 223: 'amino',\n",
       " 224: 'matrices',\n",
       " 225: 'average',\n",
       " 226: 'functional',\n",
       " 227: 'prove',\n",
       " 228: 'applied',\n",
       " 229: 'economic',\n",
       " 230: 'clusters',\n",
       " 231: 'samples',\n",
       " 232: 'important',\n",
       " 233: 'discuss',\n",
       " 234: 'alpha',\n",
       " 235: 'here',\n",
       " 236: 'asymptotic',\n",
       " 237: 'term',\n",
       " 238: 'found',\n",
       " 239: 'no',\n",
       " 240: 'existence',\n",
       " 241: 'privileged',\n",
       " 242: 'related',\n",
       " 243: 'conditions',\n",
       " 244: 'introduce',\n",
       " 245: 'network',\n",
       " 246: 'level',\n",
       " 247: 'variables',\n",
       " 248: 'those',\n",
       " 249: 'further',\n",
       " 250: 'emission',\n",
       " 251: 'possible',\n",
       " 252: 'dynamics',\n",
       " 253: 'second',\n",
       " 254: 'features',\n",
       " 255: 'techniques',\n",
       " 256: 'measure',\n",
       " 257: 'human',\n",
       " 258: 'derive',\n",
       " 259: 'dynamic',\n",
       " 260: 'point',\n",
       " 261: 'among',\n",
       " 262: 'property',\n",
       " 263: 'way',\n",
       " 264: 'they',\n",
       " 265: 'even',\n",
       " 266: 'matter',\n",
       " 267: 'since',\n",
       " 268: 'simulations',\n",
       " 269: 'pricing',\n",
       " 270: 'specification',\n",
       " 271: 'velocity',\n",
       " 272: 'strongly',\n",
       " 273: 'theoretical',\n",
       " 274: 'unknown',\n",
       " 275: 'linear',\n",
       " 276: 'size',\n",
       " 277: 'therefore',\n",
       " 278: 'measures',\n",
       " 279: 'random',\n",
       " 280: 'n',\n",
       " 281: 'p',\n",
       " 282: 'dark',\n",
       " 283: 'distributed',\n",
       " 284: 'within',\n",
       " 285: 'developed',\n",
       " 286: 'ml',\n",
       " 287: 'least',\n",
       " 288: 'light',\n",
       " 289: 'improve',\n",
       " 290: 'lower',\n",
       " 291: 'observation',\n",
       " 292: 'fit',\n",
       " 293: 'choice',\n",
       " 294: 'absorption',\n",
       " 295: 'e',\n",
       " 296: 'planetary',\n",
       " 297: 'implementation',\n",
       " 298: 'derived',\n",
       " 299: 'version',\n",
       " 300: 'bh',\n",
       " 301: 'x',\n",
       " 302: 'empirical',\n",
       " 303: 'obtained',\n",
       " 304: 'market',\n",
       " 305: 'demonstrate',\n",
       " 306: 'out',\n",
       " 307: 'us',\n",
       " 308: 'expected',\n",
       " 309: 'illustrate',\n",
       " 310: 'radiation',\n",
       " 311: 'datasets',\n",
       " 312: 'natural',\n",
       " 313: 'research',\n",
       " 314: 'trust',\n",
       " 315: 'presence',\n",
       " 316: 'effective',\n",
       " 317: 'h',\n",
       " 318: 'due',\n",
       " 319: 'genome',\n",
       " 320: 'without',\n",
       " 321: 'local',\n",
       " 322: 'changes',\n",
       " 323: 'defined',\n",
       " 324: 'often',\n",
       " 325: 'pca',\n",
       " 326: 'shown',\n",
       " 327: 'real',\n",
       " 328: 'order',\n",
       " 329: 'moreover',\n",
       " 330: 'discussed',\n",
       " 331: 'estimator',\n",
       " 332: 'allows',\n",
       " 333: 'design',\n",
       " 334: 'frequency',\n",
       " 335: 'like',\n",
       " 336: 'vector',\n",
       " 337: 'reduction',\n",
       " 338: 'adaptive',\n",
       " 339: 'l',\n",
       " 340: 'standard',\n",
       " 341: 'template',\n",
       " 342: 'convex',\n",
       " 343: 'agents',\n",
       " 344: 'maximum',\n",
       " 345: 'estimates',\n",
       " 346: 'variance',\n",
       " 347: 'cannot',\n",
       " 348: 'much',\n",
       " 349: 'covariance',\n",
       " 350: 'return',\n",
       " 351: 'mcmc',\n",
       " 352: 'formulation',\n",
       " 353: 'census',\n",
       " 354: 'mirna',\n",
       " 355: 'properties',\n",
       " 356: 'classification',\n",
       " 357: 'wave',\n",
       " 358: 'introduced',\n",
       " 359: 'would',\n",
       " 360: 'signatures',\n",
       " 361: 'establish',\n",
       " 362: 'hospitality',\n",
       " 363: 'suitable',\n",
       " 364: 'virus',\n",
       " 365: 'physical',\n",
       " 366: 'latent',\n",
       " 367: 'likelihood',\n",
       " 368: 'underlying',\n",
       " 369: 'experiments',\n",
       " 370: 'far',\n",
       " 371: 'cross',\n",
       " 372: 'processes',\n",
       " 373: 'thus',\n",
       " 374: 'potential',\n",
       " 375: 'capacity',\n",
       " 376: 'same',\n",
       " 377: 'unsupervised',\n",
       " 378: 'halos',\n",
       " 379: 'example',\n",
       " 380: 'understand',\n",
       " 381: 'small',\n",
       " 382: 'obtain',\n",
       " 383: 'factor',\n",
       " 384: 'condition',\n",
       " 385: 'variability',\n",
       " 386: 'problems',\n",
       " 387: 'component',\n",
       " 388: 'importance',\n",
       " 389: 'credit',\n",
       " 390: 'them',\n",
       " 391: 'error',\n",
       " 392: 'hierarchical',\n",
       " 393: 'variable',\n",
       " 394: 'procedures',\n",
       " 395: 'finally',\n",
       " 396: 'robust',\n",
       " 397: 'noise',\n",
       " 398: 'background',\n",
       " 399: 'terms',\n",
       " 400: 'signal',\n",
       " 401: 'article',\n",
       " 402: 'combination',\n",
       " 403: 'initial',\n",
       " 404: 'near',\n",
       " 405: 'recall',\n",
       " 406: 'substitutions',\n",
       " 407: 'statistical',\n",
       " 408: 'convergence',\n",
       " 409: 'decision',\n",
       " 410: 'object',\n",
       " 411: 'principal',\n",
       " 412: 'typical',\n",
       " 413: 'g',\n",
       " 414: 'limit',\n",
       " 415: 'describe',\n",
       " 416: 'existing',\n",
       " 417: 'discrete',\n",
       " 418: 'dependence',\n",
       " 419: 'basic',\n",
       " 420: 'points',\n",
       " 421: 'were',\n",
       " 422: 'loss',\n",
       " 423: 'regions',\n",
       " 424: 'biological',\n",
       " 425: 'theorem',\n",
       " 426: 'few',\n",
       " 427: 'black',\n",
       " 428: 'expectation',\n",
       " 429: 'could',\n",
       " 430: 'smbh',\n",
       " 431: 'addition',\n",
       " 432: 'stage',\n",
       " 433: 'leverage',\n",
       " 434: 'heterogeneity',\n",
       " 435: 'constrained',\n",
       " 436: 'context',\n",
       " 437: 'rank',\n",
       " 438: 'he',\n",
       " 439: 'nonlinear',\n",
       " 440: 'project',\n",
       " 441: 'polynomial',\n",
       " 442: 'history',\n",
       " 443: 'field',\n",
       " 444: 'br',\n",
       " 445: 'years',\n",
       " 446: 'dependent',\n",
       " 447: 'studied',\n",
       " 448: 'finance',\n",
       " 449: 'bound',\n",
       " 450: 'parties',\n",
       " 451: 'machine',\n",
       " 452: 'three',\n",
       " 453: 'comprehensive',\n",
       " 454: 'contracts',\n",
       " 455: 'multi',\n",
       " 456: 'beam',\n",
       " 457: 'hand',\n",
       " 458: 'levels',\n",
       " 459: 'range',\n",
       " 460: 'states',\n",
       " 461: 'now',\n",
       " 462: 'impact',\n",
       " 463: 'missing',\n",
       " 464: 'transcription',\n",
       " 465: 'highly',\n",
       " 466: 'policy',\n",
       " 467: 'available',\n",
       " 468: 'free',\n",
       " 469: 'correlations',\n",
       " 470: 'fundamental',\n",
       " 471: 'what',\n",
       " 472: 'identifiability',\n",
       " 473: 'w',\n",
       " 474: 'driven',\n",
       " 475: 'hold',\n",
       " 476: 'highest',\n",
       " 477: 'spectrum',\n",
       " 478: 'fast',\n",
       " 479: 'any',\n",
       " 480: 'does',\n",
       " 481: 'radial',\n",
       " 482: 'option',\n",
       " 483: 'constraints',\n",
       " 484: 'role',\n",
       " 485: 'including',\n",
       " 486: 'em',\n",
       " 487: 'stackmc',\n",
       " 488: 'ray',\n",
       " 489: 'statistics',\n",
       " 490: 'cells',\n",
       " 491: 'ad',\n",
       " 492: 'tests',\n",
       " 493: 'ca',\n",
       " 494: 'variations',\n",
       " 495: 'hb',\n",
       " 496: 'sparse',\n",
       " 497: 'equilibrium',\n",
       " 498: 'supervised',\n",
       " 499: 'galaxy',\n",
       " 500: 'variation',\n",
       " 501: 'previously',\n",
       " 502: 'inspired',\n",
       " 503: 'examples',\n",
       " 504: 'slack',\n",
       " 505: 'whether',\n",
       " 506: 'equation',\n",
       " 507: 'adjusted',\n",
       " 508: 'portfolio',\n",
       " 509: 'identified',\n",
       " 510: 'access',\n",
       " 511: 'gap',\n",
       " 512: 'comes',\n",
       " 513: 'sos',\n",
       " 514: 'digital',\n",
       " 515: 'types',\n",
       " 516: 'poor',\n",
       " 517: 'icv',\n",
       " 518: 'surface',\n",
       " 519: 'sources',\n",
       " 520: 'trained',\n",
       " 521: 'temperature',\n",
       " 522: 'following',\n",
       " 523: 'feature',\n",
       " 524: 'sequence',\n",
       " 525: 'need',\n",
       " 526: 'regular',\n",
       " 527: 'items',\n",
       " 528: 'setting',\n",
       " 529: 'v',\n",
       " 530: 'representation',\n",
       " 531: 'around',\n",
       " 532: 'antibody',\n",
       " 533: 'antibodies',\n",
       " 534: 'earth',\n",
       " 535: 'phase',\n",
       " 536: 'asset',\n",
       " 537: 'product',\n",
       " 538: 'report',\n",
       " 539: 'key',\n",
       " 540: 'external',\n",
       " 541: 'strong',\n",
       " 542: 'isotropic',\n",
       " 543: 'stationary',\n",
       " 544: 'final',\n",
       " 545: 'tested',\n",
       " 546: 'conventional',\n",
       " 547: 'connection',\n",
       " 548: 'tissue',\n",
       " 549: 'mechanism',\n",
       " 550: 'um',\n",
       " 551: 'planets',\n",
       " 552: 'extend',\n",
       " 553: 'house',\n",
       " 554: 'streams',\n",
       " 555: 'excess',\n",
       " 556: 'via',\n",
       " 557: 'multicategory',\n",
       " 558: 'package',\n",
       " 559: 'full',\n",
       " 560: 'collateral',\n",
       " 561: 'accuracy',\n",
       " 562: 'during',\n",
       " 563: 'means',\n",
       " 564: 'motion',\n",
       " 565: 'continuous',\n",
       " 566: 'included',\n",
       " 567: 'taking',\n",
       " 568: 'spaces',\n",
       " 569: 'loci',\n",
       " 570: 'run',\n",
       " 571: 'post',\n",
       " 572: 'mean',\n",
       " 573: 'shifts',\n",
       " 574: 'parameter',\n",
       " 575: 'stochastic',\n",
       " 576: 'should',\n",
       " 577: 'approaches',\n",
       " 578: 'utility',\n",
       " 579: 'employer',\n",
       " 580: 'let',\n",
       " 581: 'good',\n",
       " 582: 'short',\n",
       " 583: 'mixed',\n",
       " 584: 'necessary',\n",
       " 585: 'increasing',\n",
       " 586: 'prior',\n",
       " 587: 'item',\n",
       " 588: 'do',\n",
       " 589: 'outcome',\n",
       " 590: 'upon',\n",
       " 591: 'mc',\n",
       " 592: 'stellar',\n",
       " 593: 'ratio',\n",
       " 594: 'output',\n",
       " 595: 'intervention',\n",
       " 596: 'achieved',\n",
       " 597: 'part',\n",
       " 598: 'off',\n",
       " 599: 'similar',\n",
       " 600: 'reduce',\n",
       " 601: 'learn',\n",
       " 602: 'relationship',\n",
       " 603: 'depends',\n",
       " 604: 'probabilities',\n",
       " 605: 'career',\n",
       " 606: 'sites',\n",
       " 607: 'modeling',\n",
       " 608: 'across',\n",
       " 609: 'hole',\n",
       " 610: 'tumor',\n",
       " 611: 'rcv',\n",
       " 612: 'widely',\n",
       " 613: 'differential',\n",
       " 614: 'determine',\n",
       " 615: 'molecular',\n",
       " 616: 'single',\n",
       " 617: 'primarily',\n",
       " 618: 'dissolved',\n",
       " 619: 'though',\n",
       " 620: 'compare',\n",
       " 621: 'predictions',\n",
       " 622: 'rdf',\n",
       " 623: 'structural',\n",
       " 624: 'equations',\n",
       " 625: 'posterior',\n",
       " 626: 'extraction',\n",
       " 627: 'expressed',\n",
       " 628: 'sets',\n",
       " 629: 'index',\n",
       " 630: 'genomes',\n",
       " 631: 'bf',\n",
       " 632: 'four',\n",
       " 633: 'his',\n",
       " 634: 'measurements',\n",
       " 635: 'asymmetry',\n",
       " 636: 'diffusion',\n",
       " 637: 'done',\n",
       " 638: 'literature',\n",
       " 639: 'compared',\n",
       " 640: 'economy',\n",
       " 641: 'larger',\n",
       " 642: 'protrusion',\n",
       " 643: 'indicators',\n",
       " 644: 'markov',\n",
       " 645: 'multivariate',\n",
       " 646: 'nature',\n",
       " 647: 'tools',\n",
       " 648: 'amount',\n",
       " 649: 'ntcp',\n",
       " 650: 'canadian',\n",
       " 651: 'upper',\n",
       " 652: 'chemical',\n",
       " 653: 'step',\n",
       " 654: 'stable',\n",
       " 655: 'transition',\n",
       " 656: 'heterogeneous',\n",
       " 657: 'furthermore',\n",
       " 658: 'clinical',\n",
       " 659: 'estimators',\n",
       " 660: 'definite',\n",
       " 661: 'quantitative',\n",
       " 662: 'produce',\n",
       " 663: 'remains',\n",
       " 664: 'about',\n",
       " 665: 'resulting',\n",
       " 666: 'calculate',\n",
       " 667: 'times',\n",
       " 668: 'doppler',\n",
       " 669: 'cooperative',\n",
       " 670: 'strategies',\n",
       " 671: 'proposes',\n",
       " 672: 'stages',\n",
       " 673: 'settings',\n",
       " 674: 'agreement',\n",
       " 675: 'amplitude',\n",
       " 676: 'above',\n",
       " 677: 'grbs',\n",
       " 678: 'profile',\n",
       " 679: 'deep',\n",
       " 680: 'although',\n",
       " 681: 'seen',\n",
       " 682: 'augmentation',\n",
       " 683: 'bounds',\n",
       " 684: 'root',\n",
       " 685: 'computationally',\n",
       " 686: 'greedy',\n",
       " 687: 'instead',\n",
       " 688: 'ngc',\n",
       " 689: 'source',\n",
       " 690: 'events',\n",
       " 691: 'super',\n",
       " 692: 'players',\n",
       " 693: 'estimating',\n",
       " 694: 'cure',\n",
       " 695: 'beta',\n",
       " 696: 'slow',\n",
       " 697: 'personalized',\n",
       " 698: 'implementations',\n",
       " 699: 'socioeconomic',\n",
       " 700: 'realized',\n",
       " 701: 'specifically',\n",
       " 702: 'period',\n",
       " 703: 'mg',\n",
       " 704: 'groups',\n",
       " 705: 'neutral',\n",
       " 706: 'combining',\n",
       " 707: 'patterns',\n",
       " 708: 'mar',\n",
       " 709: 'infrared',\n",
       " 710: 'programming',\n",
       " 711: 'reversibility',\n",
       " 712: 'radio',\n",
       " 713: 'industry',\n",
       " 714: 'resilience',\n",
       " 715: 'fdr',\n",
       " 716: 'd',\n",
       " 717: 'extragalactic',\n",
       " 718: 'valid',\n",
       " 719: 'diffuse',\n",
       " 720: 'likely',\n",
       " 721: 'worker',\n",
       " 722: 'exist',\n",
       " 723: 'require',\n",
       " 724: 'perform',\n",
       " 725: 'traditional',\n",
       " 726: 'certain',\n",
       " 727: 'hence',\n",
       " 728: 'et',\n",
       " 729: 'power',\n",
       " 730: 'relaxation',\n",
       " 731: 'detected',\n",
       " 732: 'easily',\n",
       " 733: 'moments',\n",
       " 734: 'principle',\n",
       " 735: 'tvarcv',\n",
       " 736: 'explained',\n",
       " 737: 'directly',\n",
       " 738: 'ips',\n",
       " 739: 'representations',\n",
       " 740: 'controls',\n",
       " 741: 'ce',\n",
       " 742: 'weather',\n",
       " 743: 'motivated',\n",
       " 744: 'alternative',\n",
       " 745: 'made',\n",
       " 746: 'covolatility',\n",
       " 747: 'cost',\n",
       " 748: 'breaking',\n",
       " 749: 'matching',\n",
       " 750: 'al',\n",
       " 751: 'sensitive',\n",
       " 752: 'integral',\n",
       " 753: 'uncertainty',\n",
       " 754: 'keywords',\n",
       " 755: 'days',\n",
       " 756: 'governed',\n",
       " 757: 'permutation',\n",
       " 758: 'pastur',\n",
       " 759: 'hpv',\n",
       " 760: 'presents',\n",
       " 761: 'novel',\n",
       " 762: 'accounts',\n",
       " 763: 'continuity',\n",
       " 764: 'web',\n",
       " 765: 'minimization',\n",
       " 766: 'milky',\n",
       " 767: 'components',\n",
       " 768: 'sharing',\n",
       " 769: 'dimensions',\n",
       " 770: 'possibility',\n",
       " 771: 'abundance',\n",
       " 772: 'partial',\n",
       " 773: 'critical',\n",
       " 774: 'starting',\n",
       " 775: 'practice',\n",
       " 776: 'jobs',\n",
       " 777: 'collaborative',\n",
       " 778: 'situations',\n",
       " 779: 'depend',\n",
       " 780: 'protein',\n",
       " 781: 'planet',\n",
       " 782: 'who',\n",
       " 783: 'come',\n",
       " 784: 'finding',\n",
       " 785: 'length',\n",
       " 786: 'reference',\n",
       " 787: 'solution',\n",
       " 788: 'incentives',\n",
       " 789: 'future',\n",
       " 790: 'evolution',\n",
       " 791: 'frequent',\n",
       " 792: 'capital',\n",
       " 793: 'fraction',\n",
       " 794: 'word',\n",
       " 795: 'conclude',\n",
       " 796: 'varied',\n",
       " 797: 'ii',\n",
       " 798: 'gamboostlss',\n",
       " 799: 'massif',\n",
       " 800: 'target',\n",
       " 801: 'cues',\n",
       " 802: 'wavelength',\n",
       " 803: 'treatments',\n",
       " 804: 'concept',\n",
       " 805: 'attraction',\n",
       " 806: 'practitioners',\n",
       " 807: 'massive',\n",
       " 808: 'proof',\n",
       " 809: 'activity',\n",
       " 810: 'quantile',\n",
       " 811: 'correlation',\n",
       " 812: 'commonly',\n",
       " 813: 'fe',\n",
       " 814: 'making',\n",
       " 815: 'world',\n",
       " 816: 'perceptions',\n",
       " 817: 'clear',\n",
       " 818: 'malliavin',\n",
       " 819: 'less',\n",
       " 820: 'generalized',\n",
       " 821: 'bidders',\n",
       " 822: 'leads',\n",
       " 823: 'boundary',\n",
       " 824: 'variants',\n",
       " 825: 'increase',\n",
       " 826: 'fluctuations',\n",
       " 827: 'hard',\n",
       " 828: 'cml',\n",
       " 829: 'originate',\n",
       " 830: 'ddr',\n",
       " 831: 'images',\n",
       " 832: 'rare',\n",
       " 833: 'students',\n",
       " 834: 'check',\n",
       " 835: 'become',\n",
       " 836: 'kidney',\n",
       " 837: 'curve',\n",
       " 838: 'trade',\n",
       " 839: 'calculus',\n",
       " 840: 'methodology',\n",
       " 841: 'common',\n",
       " 842: 'outcomes',\n",
       " 843: 'patient',\n",
       " 844: 'identify',\n",
       " 845: 'tourism',\n",
       " 846: 'rates',\n",
       " 847: 'regulatory',\n",
       " 848: 'trades',\n",
       " 849: 'afford',\n",
       " 850: 'occurs',\n",
       " 851: 'densities',\n",
       " 852: 'determined',\n",
       " 853: 'microcredit',\n",
       " 854: 'dynamical',\n",
       " 855: 'logistic',\n",
       " 856: 'absolute',\n",
       " 857: 'annuity',\n",
       " 858: 'perfect',\n",
       " 859: 'panel',\n",
       " 860: 'needed',\n",
       " 861: 'targeting',\n",
       " 862: 'individual',\n",
       " 863: 'differentially',\n",
       " 864: 'solutions',\n",
       " 865: 'so',\n",
       " 866: 'flexible',\n",
       " 867: 'polymorphism',\n",
       " 868: 'implemented',\n",
       " 869: 'arises',\n",
       " 870: 'having',\n",
       " 871: 'easy',\n",
       " 872: 'wall',\n",
       " 873: 'targeted',\n",
       " 874: 'false',\n",
       " 875: 'gig',\n",
       " 876: 'explore',\n",
       " 877: 'debt',\n",
       " 878: 'increasingly',\n",
       " 879: 'sequenced',\n",
       " 880: 'cause',\n",
       " 881: 'annihilation',\n",
       " 882: 'mathematical',\n",
       " 883: 'either',\n",
       " 884: 'spin',\n",
       " 885: 'libor',\n",
       " 886: 'art',\n",
       " 887: 'co',\n",
       " 888: 'reject',\n",
       " 889: 'negative',\n",
       " 890: 'slope',\n",
       " 891: 'difference',\n",
       " 892: 'select',\n",
       " 893: 'kapteyn',\n",
       " 894: 'strategy',\n",
       " 895: 'periods',\n",
       " 896: 'early',\n",
       " 897: 'spectra',\n",
       " 898: 'localization',\n",
       " 899: 'ais',\n",
       " 900: 'remain',\n",
       " 901: 'switching',\n",
       " 902: 'affects',\n",
       " 903: 'development',\n",
       " 904: 'globular',\n",
       " 905: 'group',\n",
       " 906: 'apparent',\n",
       " 907: 'agent',\n",
       " 908: 'fact',\n",
       " 909: 'advantage',\n",
       " 910: 'normal',\n",
       " 911: 'odot',\n",
       " 912: 'extracellular',\n",
       " 913: 'internal',\n",
       " 914: 'b',\n",
       " 915: 't',\n",
       " 916: 'seed',\n",
       " 917: 'rv',\n",
       " 918: 'coordinate',\n",
       " 919: 'patients',\n",
       " 920: 'reliability',\n",
       " 921: 'community',\n",
       " 922: 'involved',\n",
       " 923: 'interaction',\n",
       " 924: 'scenario',\n",
       " 925: 'adaptation',\n",
       " 926: 'expansion',\n",
       " 927: 'consistent',\n",
       " 928: 'unit',\n",
       " 929: 'yields',\n",
       " 930: 'outperforms',\n",
       " 931: 'finite',\n",
       " 932: 'central',\n",
       " 933: 'make',\n",
       " 934: 'responses',\n",
       " 935: 'recalls',\n",
       " 936: 'becomes',\n",
       " 937: 'galactic',\n",
       " 938: 'family',\n",
       " 939: 'performs',\n",
       " 940: 'form',\n",
       " 941: 'up',\n",
       " 942: 'formation',\n",
       " 943: 'objects',\n",
       " 944: 'classes',\n",
       " 945: 'discrepancy',\n",
       " 946: 'mm',\n",
       " 947: 'quadrupole',\n",
       " 948: 'enko',\n",
       " 949: 'markets',\n",
       " 950: 'force',\n",
       " 951: 'oscillations',\n",
       " 952: 'insurance',\n",
       " 953: 'notion',\n",
       " 954: 'reaction',\n",
       " 955: 'scuba',\n",
       " 956: 'regime',\n",
       " 957: 'relies',\n",
       " 958: 'usual',\n",
       " 959: 'lsd',\n",
       " 960: 'disease',\n",
       " 961: 'corresponding',\n",
       " 962: 'degree',\n",
       " 963: 'complexity',\n",
       " 964: 'dose',\n",
       " 965: 'training',\n",
       " 966: 'increases',\n",
       " 967: 'spectroscopy',\n",
       " 968: 'body',\n",
       " 969: 'cluster',\n",
       " 970: 'restricted',\n",
       " 971: 'variety',\n",
       " 972: 'antipodes',\n",
       " 973: 'required',\n",
       " 974: 'global',\n",
       " 975: 'mutations',\n",
       " 976: 'serve',\n",
       " 977: 'significantly',\n",
       " 978: 'implement',\n",
       " 979: 'identity',\n",
       " 980: 'parent',\n",
       " 981: 'blood',\n",
       " 982: 'sequences',\n",
       " 983: 'merge',\n",
       " 984: 'decisions',\n",
       " 985: 'constraint',\n",
       " 986: 'sciences',\n",
       " 987: 'leading',\n",
       " 988: 'nearby',\n",
       " 989: 'factorization',\n",
       " 990: 'offer',\n",
       " 991: 'wilson',\n",
       " 992: 'derivatives',\n",
       " 993: 'im',\n",
       " 994: 'accepted',\n",
       " 995: 'temporal',\n",
       " 996: 'overall',\n",
       " 997: 'synthesis',\n",
       " 998: 'discovery',\n",
       " 999: 'imputation',\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
