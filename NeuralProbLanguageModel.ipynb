{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we will do an implementation of the neural probabilistic language model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FNN architecture\n",
    "\n",
    "The architecture of the Forward Neural Network. \n",
    "\n",
    "* $n$ context size\n",
    "* $m$ the number of features associated with each word (ex: m = 100, Each word is represented by a vector of size 100).\n",
    "* $C$ is size $|V|\\times m$\n",
    "\n",
    "$$y = b + Wx + U\\tanh(d + Hx)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x = (C(w_{t-1}), C(w_{t-2}), \\ldots, C(w_{t-n+1}))$, vector of size $m\\times(n-1)$\n",
    "* $h$ be the number of hidden units\n",
    "* $H$ Corresponds to the dense layer. $H$ has $m\\times(n-1)$ columns and $h$ rows\n",
    "* $d$ Corresponds to the dense layer. $d$ is a vector of size $h$\n",
    "* $U$ Corresponds to the second dense layer. $U$ has $h$ columns $|V|$ lines\n",
    "* W dense **(can be equal to zero)** \n",
    "* $b$ vector of size $|V|$ \n",
    "\n",
    "\n",
    "Total number of parameters\n",
    "\n",
    "$ |V |(1 + nm + h) + h(1 + (n âˆ’ 1)m)$\n",
    "\n",
    "Input data\n",
    "=====\n",
    "\n",
    "For n=4\n",
    "\n",
    "$$D = [(2, 10, 3, 5), (8, 30, 2, 20), ...]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "from nplm import neurnetmodel as Neur\n",
    "nb_features = 2\n",
    "dict_size = 5\n",
    "context_size = 5\n",
    "h = 20 # The number of hidden units\n",
    "N = Neur.Network([Neur.ProjectVectors(dict_size, nb_features),\n",
    "                  Neur.ConcatProjections(), \n",
    "                  Neur.Dense(nb_features * (context_size-1), h), \n",
    "                  Neur.Tanh(), Neur.Dense(h, dict_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input vectors look like this\n",
    "X = np.array([[0, 0, 1, 0, 0], [0,1, 0, 0, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 0]])\n",
    "X = X.T\n",
    "X = np.array([X, X, X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 1, 0]],\n",
       "\n",
       "       [[0, 0, 0, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 1, 0]],\n",
       "\n",
       "       [[0, 0, 0, 1],\n",
       "        [0, 1, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 1, 0]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.60815078, -3.60815078, -3.60815078],\n",
       "       [ 3.70375656,  3.70375656,  3.70375656],\n",
       "       [-0.4153328 , -0.4153328 , -0.4153328 ],\n",
       "       [ 2.4245358 ,  2.4245358 ,  2.4245358 ],\n",
       "       [-0.38709004, -0.38709004, -0.38709004]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output vectors look like this\n",
    "Y = np.array([[0, 0, 1, 0, 0], [0,1, 0, 0, 0], [0, 0, 0, 0, 1]])\n",
    "Y = Y.T\n",
    "N_a=Neur.Network([N,Neur.Ilogit_and_KL(Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.024379019014331"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_a.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.49916018e-01, -3.41331596e+00, -5.78717943e+00,  0.00000000e+00,\n",
       "        4.36670815e+00, -3.66315494e+00,  2.40974064e+00,  4.43578581e+00,\n",
       "        0.00000000e+00, -5.11369573e+00, -7.53203803e-05, -8.92457906e-05,\n",
       "        1.60789008e-05, -1.83648317e-04,  2.72299418e-05, -6.30948772e-05,\n",
       "       -5.77634105e-05,  2.72280326e-05,  2.14671423e-03,  2.54360385e-03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient = N_a.backward(None)[0]\n",
    "gradient[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n"
     ]
    }
   ],
   "source": [
    "print(len(gradient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500292991360365\n",
      "0.2976649653220803\n",
      "0.08257019942768073\n",
      "0.14523603725477274\n",
      "0.048913994990833654\n",
      "0.10963832982273058\n",
      "0.04405780644131758\n",
      "0.2169164561448086\n",
      "0.027237449276053788\n",
      "0.01493925806953722\n",
      "0.22115014961248058\n",
      "0.058307322615911095\n",
      "0.1224352379263049\n",
      "0.27541666263628917\n",
      "0.3580144371413932\n",
      "0.7340034589913387\n",
      "0.541896530713164\n",
      "0.10483467707414681\n",
      "0.018977081812186186\n",
      "0.0005117745557910169\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    # Set a random parameter vector\n",
    "    n = N_a.nb_params\n",
    "    theta = np.random.random(n)\n",
    "    N_a.set_params(theta)\n",
    "    # Get a random direction\n",
    "    d = np.random.random(n)\n",
    "    d = d / np.linalg.norm(d)\n",
    "    # Compute theoretical and numerical gradients\n",
    "    theor_deriv = np.dot(N_a.backward(None)[0], d)\n",
    "    h = 1e-10\n",
    "    Ftheta = N_a.forward(X)\n",
    "    N_a.set_params(theta + h*d)\n",
    "    Ftheta_plus_hd = N_a.forward(X)\n",
    "    num_deriv = (Ftheta_plus_hd - Ftheta) / h\n",
    "    print(np.linalg.norm(num_deriv - theor_deriv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
